<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Awais


</title>
<meta name="description" content="Personal website. 
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü§ñ</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2PRP5MSJ91"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-2PRP5MSJ91');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:%69%61%77%61%69%73%72%61%75%66@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=bA-9t1cAAAAJ&hl" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/awaisrauf" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/deepawais" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>




<a href="https://openreview.net/profile?id=~Muhammad_Awais2" target="_blank" title="Work"><i class="fas fa-briefcase"></i></a>






        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     Awais
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg">
      
      
        <div class="address">
          iawaisrauf at gmail dot com
        </div>
      
    </div>
    

    <div class="clearfix">
      <style>
  /*Style for muted links*/
  .muted-link {
    color: #888; /*Muted gray color*/
    text-decoration: none; /*Remove underline*/
  }
  /*Style for muted links when hovered over*/
  .muted-link:hover {
    color: #555; /*Darker gray color when hovering*/
  }
</style>

<p>I am a research associate at MBZUAI (<a href="https://csrankings.org/#/index?ai&amp;vision&amp;mlmining&amp;nlp&amp;world">among top 20 AI research institutes</a>).</p>

<p>Previously, I was</p>
<ul>
  <li> RA at <a href="https://ai.sony/">Sony AI</a>, Japan
  </li>
  <li> RA at AI Theory Group of <a href="http://www.noahlab.com.hk/">Huawei's Noah Ark Lab</a> in Hong Kong
  </li>
  <li> Ph.D. Student and RA at <a href="https://sites.google.com/khu.ac.kr/mlvclab/">MLVC Lab</a> in South Korea
  </li>
  <li> RA at <a href="http://www.spider.itu.edu.pk">SPIDER Lab</a> and a TA for five grad and undergrad courses, including <a href="https://awaisrauf.github.io/ee512/" class="muted-link">machine learning</a> at <a href="http://www.itu.edu.pk/" class="muted-link">ITU </a>
  </li>
  <!-- <li> Teaching Assistant for graduate and undergraduate courses, including <a href="https://awaisrauf.github.io/ee512/" class="muted-link">machine learning</a> -->
</ul>

<p>I have published my research in top venues, including <a href="">NeurIPS</a>, <a href="">ICCV</a>, and <a href="">TNNLS</a>. And I have served as a reviewer in CVPR, ICLR, ICCV and NeurIPS. I also won <a href="https://awaisrauf.github.io/election_prediction">üìäa national-level ml competition</a>, <a href="https://sites.google.com/view/2022-workshop-bridgingmathstcs">‚úàÔ∏è a travel grant to attend AustMS</a> and <a href="https://developer.nvidia.com/academic_gpu_seeding">üñ• NVIDIA‚Äôs GPU grant</a> for research.</p>

<p>I am fourtunate that I get to work with amazing people: <a href="https://sites.google.com/view/lingjuan-lyu/home" class="muted-link"> Dr. Lingjuan </a> and <a href="https://weiming.me" class="muted-link"> Dr. Weiming </a> at Sony AI, <a href="https://scholar.google.com.hk/citations?user=1M00Yg8AAAAJ&amp;hl=zh-TW" class="muted-link"> Dr. Fengwei</a>, <a href="https://scholar.google.com/citations?user=_fgE3u8AAAAJ&amp;hl=en" class="muted-link"> Dr. Chuanlong</a>, <a href="https://scholar.google.com/citations?user=XboZC1AAAAAJ&amp;hl=en" class="muted-link"> Dr. Zhenguo</a>, and <a href="https://scholar.google.com.hk/citations?user=aXdjxb4AAAAJ&amp;hl=en" class="muted-link"> Prof. Luo</a> at Huawei, <a href="https://scholar.google.co.kr/citations?user=EULut5oAAAAJ&amp;hl=ko" class="muted-link"> Prof. Sung-Ho</a> for Ph.D. supervision, and <a href="https://itu.edu.pk/faculty-itu/dr-ali-ahmed/" class="muted-link"> Dr. Ali </a> and <a href="http://usamabinsikandar.weebly.com/teaching.html" class="muted-link"> Dr. Usama </a> at ITU.</p>

<p>I also like <a href="https://www.goodreads.com/review/list/90419452-awais?page=1&amp;per_page=100&amp;print=true&amp;ref=nav_mybooks&amp;shelf=read&amp;utf8">üìñ reading</a>, <a href="">üèõ traveling</a>, üßë‚Äçüíª coding and üë∑üèº‚Äç‚ôÇÔ∏è building stuff.</p>

    </div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  

  </div>

  <div id="Awais.arXiv23" class="col-sm-8">
    
      <div class="title">Foundational Models Defining a New Era in Vision: A Survey and Outlook</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Muzammal, Naseer,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Khan, Salman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anwer, Rao Muhammad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Cholakkal, Hisham,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shah, Mubarak,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yang, Ming-Hsuan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Khan, Fahad Shahbaz
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review (arXiv)</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2307.13721.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/awaisrauf/Awesome-CV-Foundational-Models" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  

  </div>

  <div id="Awais.arXiv" class="col-sm-8">
    
      <div class="title">FROD: Robust Object Detection for Free</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Weiming, Zhuang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lingjuan, ,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lyu, ,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sung-Ho, Bae
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review (arXiv)</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  

  </div>

  <div id="Awais.NeurIPS22" class="col-sm-8">
    
      <div class="title">ZooD: Exploiting model zoo for out-of-distribution generalization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Qishi, Dong*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  *, ,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhou, Fengwei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xie, Chuanlong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hu, Tianyang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yang, Yongxin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sung-Ho, Bae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Li, Zhenguo
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Neural Information Processing Systems (NeurIPS)</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/cd305fdee96836d5cc1de94577d71b61-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  

  </div>

  <div id="Awais.NeurIPS" class="col-sm-8">
    
      <div class="title">MixACM: Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fengwei, Zhou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chuanlong, Xie,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jiawei, Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sung-Ho, Bae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zhenguo, Li
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Neural Information Processing Systems (NeurIPS)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/240c945bb72980130446fc2b40fbb8e0-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep neural networks are susceptible to adversarially crafted, small and imperceptible changes in the natural inputs. The most effective defense mechanism against these examples is adversarial training which constructs adversarial examples during training by iterative maximization of loss. The model is then trained to minimize the loss on these constructed examples. This min-max optimization requires more data, larger capacity models, and additional computing resources. It also degrades the standard generalization performance of a model. Can we achieve robustness more efficiently? In this work, we explore this question from the perspective of knowledge transfer. First, we theoretically show the transferability of robustness from an adversarially trained teacher model to a student model with the help of mixup augmentation. Second, we propose a novel robustness transfer method called Mixup-Based Activated Channel Maps (MixACM) Transfer. MixACM transfers robustness from a robust teacher to a student by matching activated channel maps generated without expensive adversarial perturbations. Finally, extensive experiments on multiple datasets and different learning scenarios show our method can transfer robustness while also improving generalization on natural images.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICCV</abbr>
    
  

  </div>

  <div id="Awais.ICCV21" class="col-sm-8">
    
      <div class="title">Adversarial Robustness for Unsupervised Domain Adaptation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fengwei, Zhou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hang, Xu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lanqing, Hong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ping, Luo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sung-Ho, Bae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zhenguo, Li
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Internatioanl Conference on Computer Vision (ICCV)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://awaisrauf.github.io/robust_uda" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://arxiv.org/pdf/2109.00946.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Extensive Unsupervised Domain Adaptation (UDA) studies have shown great success in practice by learning transferable representations across a labeled source domain and an unlabeled target domain with deep models. However, previous works focus on improving the generalization ability of UDA models on clean examples without considering the adversarial robustness, which is crucial in real-world applications. Conventional adversarial training methods are not suitable for the adversarial robustness on the unlabeled target domain of UDA since they train models with adversarial examples generated by the supervised loss function. In this work, we leverage intermediate representations learned by multiple robust ImageNet models to improve the robustness of UDA models. Our method works by aligning the features of the UDA model with the robust features learned by ImageNet pre-trained models along with domain adaptation training. It utilizes both labeled and unlabeled domains and instills robustness without any adversarial intervention or label requirement during domain adaptation training. Experimental results show that our method significantly improves adversarial robustness compared to the baseline while keeping clean accuracy on various UDA benchmarks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TNNLS</abbr>
    
  

  </div>

  <div id="Awais.TNNLS20" class="col-sm-8">
    
      <div class="title">Revisiting Internal Covariant Shift for Batch Normalization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Md. Tauhid Bin, Iqbal,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sung-Ho, Bae
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9238401" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite the success of Batch Normalization (BatchNorm) and a plethora of its variants, the exact reasons for its success are still shady. The original BatchNorm paper explained it as a mechanism that reduces the Internal Covariate Shift (ICS), i.e., the distribution shifts in the input of the layers during training. Recently, some papers manifested skepticism on this hypothesis and provided \textitalternative explanations for the success of BatchNorm, such as the applicability of very high learning rates and the ability to smooth the landscape in optimization. In this work, we counter this  textit alternative arguments by demonstrating the importance of reduction in ICS following an empirical approach. We demonstrated various ways to achieve the above-mentioned alternative properties without any performance boost. In this light, we explored the importance of different BatchNorm parameters (i.e., batch statistics, affine transformation parameters) by visualizing their effectiveness in the performance and analyzed their connections with ICS. Afterward, we showed a different normalization scheme that fulfills all alternative explanations except reduction in ICS. Despite having all the alternative properties, we observed its poor performance, which nullifies the alternative claims rather signifies the importance of the ICS reduction. We performed comprehensive experiments on many variants of BatchNorm, finding that all of them similarly reduce ICS.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  

  </div>

  <div id="Awais.Arxiv20" class="col-sm-8">
    
      <div class="title">Towards Adversarially Robust Normalization Approach</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fahad, Shamshad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sung-Ho, Bae
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2006.11007.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Batch Normalization (BatchNorm) is effective for improving performance and accelerating the training of deep neural networks. However, it is also a cause of adversarial vulnerability. In this paper, we first investigated how BatchNorm causes this vulnerability. We observed that adversarial inputs tend to shift the distributions of the BatchNorm layer. This shift makes train-time estimated statistics of BatchNorm inaccurate. We hypothesize that these inaccurate statistics make models with BatchNorm more vulnerable to adversarial attacks. We empirically verified our hypothesis by conducting multiple experiments on a diverse set of architectures and datasets. Based on the insights from these experiments, we also proposed a robust version of BatchNorm. We experimentally show that models trained with RobustNorm perform better under adversarial settings while retaining the benefits of BatchNorm.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2023 Awais  .
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
