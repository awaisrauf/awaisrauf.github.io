<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Awais


  | publications

</title>
<meta name="description" content="Personal website. 
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->
<link rel="stylesheet" href="/assets/css/github.css">

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2PRP5MSJ91"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-2PRP5MSJ91');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="//">
       Awais
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          <!-- Blog Button -->
          <li class="nav-item">
            <a class="nav-link" href="https://awaisrauf.github.io/deepCuriosity/" target="_blank">
              blog
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">for more details, please visit my <a href="https://scholar.google.com.hk/citations?user=bA-9t1cAAAAJ&hl=en"><u>Google Scholar</u></a> or <a href="https://openreview.net/profile?id=~Muhammad_Awais2"> <u>OpenReview</u> </a> page.</p>
  </header>

  <article>
    <div class="publications">

<ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  

  </div>

  <div id="Awais.arXiv23" class="col-sm-8">
    
      <div class="title">Foundational Models Defining a New Era in Vision: A Survey and Outlook</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Muzammal, Naseer,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Khan, Salman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Anwer, Rao Muhammad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Cholakkal, Hisham,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shah, Mubarak,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yang, Ming-Hsuan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Khan, Fahad Shahbaz
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2307.13721.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/awaisrauf/Awesome-CV-Foundational-Models" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  

  </div>

  <div id="Awais.arXiv" class="col-sm-8">
    
      <div class="title">FROD: Robust Object Detection for Free</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Weiming, Zhuang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lingjuan, ,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lyu, ,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sung-Ho, Bae
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review (arXiv)</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  

  </div>

  <div id="Awais.NeurIPS22" class="col-sm-8">
    
      <div class="title">ZooD: Exploiting model zoo for out-of-distribution generalization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Qishi, Dong*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  *, ,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhou, Fengwei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xie, Chuanlong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hu, Tianyang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yang, Yongxin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sung-Ho, Bae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Li, Zhenguo
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Neural Information Processing Systems (NeurIPS)</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/cd305fdee96836d5cc1de94577d71b61-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  

  </div>

  <div id="Awais.NeurIPS" class="col-sm-8">
    
      <div class="title">MixACM: Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fengwei, Zhou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chuanlong, Xie,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jiawei, Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sung-Ho, Bae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zhenguo, Li
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Neural Information Processing Systems (NeurIPS)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/240c945bb72980130446fc2b40fbb8e0-Paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep neural networks are susceptible to adversarially crafted, small and imperceptible changes in the natural inputs. The most effective defense mechanism against these examples is adversarial training which constructs adversarial examples during training by iterative maximization of loss. The model is then trained to minimize the loss on these constructed examples. This min-max optimization requires more data, larger capacity models, and additional computing resources. It also degrades the standard generalization performance of a model. Can we achieve robustness more efficiently? In this work, we explore this question from the perspective of knowledge transfer. First, we theoretically show the transferability of robustness from an adversarially trained teacher model to a student model with the help of mixup augmentation. Second, we propose a novel robustness transfer method called Mixup-Based Activated Channel Maps (MixACM) Transfer. MixACM transfers robustness from a robust teacher to a student by matching activated channel maps generated without expensive adversarial perturbations. Finally, extensive experiments on multiple datasets and different learning scenarios show our method can transfer robustness while also improving generalization on natural images.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICCV</abbr>
    
  

  </div>

  <div id="Awais.ICCV21" class="col-sm-8">
    
      <div class="title">Adversarial Robustness for Unsupervised Domain Adaptation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fengwei, Zhou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hang, Xu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lanqing, Hong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ping, Luo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sung-Ho, Bae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zhenguo, Li
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Internatioanl Conference on Computer Vision (ICCV)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://awaisrauf.github.io/robust_uda" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://arxiv.org/pdf/2109.00946.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Extensive Unsupervised Domain Adaptation (UDA) studies have shown great success in practice by learning transferable representations across a labeled source domain and an unlabeled target domain with deep models. However, previous works focus on improving the generalization ability of UDA models on clean examples without considering the adversarial robustness, which is crucial in real-world applications. Conventional adversarial training methods are not suitable for the adversarial robustness on the unlabeled target domain of UDA since they train models with adversarial examples generated by the supervised loss function. In this work, we leverage intermediate representations learned by multiple robust ImageNet models to improve the robustness of UDA models. Our method works by aligning the features of the UDA model with the robust features learned by ImageNet pre-trained models along with domain adaptation training. It utilizes both labeled and unlabeled domains and instills robustness without any adversarial intervention or label requirement during domain adaptation training. Experimental results show that our method significantly improves adversarial robustness compared to the baseline while keeping clean accuracy on various UDA benchmarks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TNNLS</abbr>
    
  

  </div>

  <div id="Awais.TNNLS20" class="col-sm-8">
    
      <div class="title">Revisiting Internal Covariant Shift for Batch Normalization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Md. Tauhid Bin, Iqbal,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sung-Ho, Bae
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9238401" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite the success of Batch Normalization (BatchNorm) and a plethora of its variants, the exact reasons for its success are still shady. The original BatchNorm paper explained it as a mechanism that reduces the Internal Covariate Shift (ICS), i.e., the distribution shifts in the input of the layers during training. Recently, some papers manifested skepticism on this hypothesis and provided \textitalternative explanations for the success of BatchNorm, such as the applicability of very high learning rates and the ability to smooth the landscape in optimization. In this work, we counter this  textit alternative arguments by demonstrating the importance of reduction in ICS following an empirical approach. We demonstrated various ways to achieve the above-mentioned alternative properties without any performance boost. In this light, we explored the importance of different BatchNorm parameters (i.e., batch statistics, affine transformation parameters) by visualizing their effectiveness in the performance and analyzed their connections with ICS. Afterward, we showed a different normalization scheme that fulfills all alternative explanations except reduction in ICS. Despite having all the alternative properties, we observed its poor performance, which nullifies the alternative claims rather signifies the importance of the ICS reduction. We performed comprehensive experiments on many variants of BatchNorm, finding that all of them similarly reduce ICS.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  

  </div>

  <div id="Awais.Arxiv20" class="col-sm-8">
    
      <div class="title">Towards Adversarially Robust Normalization Approach</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fahad, Shamshad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sung-Ho, Bae
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2006.11007.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Batch Normalization (BatchNorm) is effective for improving performance and accelerating the training of deep neural networks. However, it is also a cause of adversarial vulnerability. In this paper, we first investigated how BatchNorm causes this vulnerability. We observed that adversarial inputs tend to shift the distributions of the BatchNorm layer. This shift makes train-time estimated statistics of BatchNorm inaccurate. We hypothesize that these inaccurate statistics make models with BatchNorm more vulnerable to adversarial attacks. We empirically verified our hypothesis by conducting multiple experiments on a diverse set of architectures and datasets. Based on the insights from these experiments, we also proposed a robust version of BatchNorm. We experimentally show that models trained with RobustNorm perform better under adversarial settings while retaining the benefits of BatchNorm.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">JAIHC</abbr>
    
  

  </div>

  <div id="Awais.JAIHC.19" class="col-sm-8">
    
      <div class="title">Leveraging big data for politics: predicting general election of Pakistan using a novel rigged model</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Saeed UL, Hassan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ali, Ahmed
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Journal of Ambient Intelligence and Humanized Computing</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://awaisrauf.github.io/election_prediction" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICCVw</abbr>
    
  

  </div>

  <div id="Fahad.ICCVw.19" class="col-sm-8">
    
      <div class="title">Adaptive Ptych: Leveraging Image Adaptive Generative Priors for Subsampled Fourier Ptychography</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Fahad, Shamshad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Asif, Hanif,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Farwa, Abbas,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ali, Ahmed
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Conference on Computer Vision Workshops</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/LCI/Shamshad_Adaptive_Ptych_Leveraging_Image_Adaptive_Generative_Priors_for_Subsampled_Fourier_ICCVW_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently pretrained generative models have shown promising results for subsampled Fourier Ptychography (FP) in terms of quality of reconstruction for extremely low sampling rates. However, the representation capabilities of these pretrained generators do not capture the full distribution for complex classes of images, such as human faces or numbers, resulting in representation error. Moreover, recent studies have shown that these pretrained generative priors struggle at high-resolution in imaging inverse problems for reconstructing a faithful estimate of the true image, potentially due to mode collapse issue. To mitigate the issue of representation error of pretrained generative models for subsampled FP, we propose to make pretrained generator image adaptive by modifying it to better represent a single image (at test time) that is consistent with the subsampled FP measurements. Our experimental results demonstrate the superiority of the proposed approach over recent subsampled FP methods in terms of both quantitative metrics and visual quality</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NIPSw</abbr>
    
  

  </div>

  <div id="Fahad.NIPSw.18" class="col-sm-8">
    
      <div class="title">Leveraging Deep Steinâ€™s Unbiased Risk Estimator for Unsupervised X-ray Denoising</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Fahad, Shamshad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Muhammad, Asim,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ali, Ahmed
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Neural Information Processing Systems Workshops</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="http://awaisrauf.github.io/xray-denoising" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICTD</abbr>
    
  

  </div>

  <div id="Asim.ICTD.17" class="col-sm-8">
    
      <div class="title">Introducing Data mining for Predicting trends in School Education of Pakistan: Preliminary results and Future Directions</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Muhammad, Asim,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fahad, Shamshad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Ali, Ahmed
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Information and Communication Technologies and Development </em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://dl.acm.org/doi/10.1145/3136560.3136597" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2024 Awais  .
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
