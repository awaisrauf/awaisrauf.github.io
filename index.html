<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Awais


</title>
<meta name="description" content="Personal website. 
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2PRP5MSJ91"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-2PRP5MSJ91');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
        <!-- Social Icons -->
        <div class="navbar-brand social">
          <a href="mailto:%69%61%77%61%69%73%72%61%75%66@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=bA-9t1cAAAAJ&hl" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/awaisrauf" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/deepawais" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>











        </div>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     Awais
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg">
      
      
        <div class="address">
          iawaisrauf at gmail dot com
        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I am an assistant researcher at AI Theory Group of <a href="http://www.noahlab.com.hk/">Huaweiâ€™s Noah Ark Lab</a> in Hong Kong and a third-year Ph.D. student at Machine Learning and Visual Computing <a href="https://sites.google.com/khu.ac.kr/mlvclab/">(MLVC)</a> Lab in South Korea.</p>

<p>Previously, I served as a research associate at the Signal Processing and Information Decoding Research - <a href="(http://www.spider.itu.edu.pk)">SPIDER</a>, Lab located in <a href="http://www.itu.edu.pk/">Information Technology University</a>. During my MS, I was a teaching assistant for two graduate courses taught by <a href="https://itu.edu.pk/faculty-itu/dr-ali-ahmed/">Dr. Ali Ahmed</a> (advance signal processing and <a href="https://awaisrauf.github.io/ee512/">machine learning</a>) and three undergraduate courses taught by <a href="http://usamabinsikandar.weebly.com/teaching.html">Usama Bin Sikandar</a>.</p>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> Sep,&nbsp2022 </th>
            <td>
              
                One paper got accepted at the Neural Information Processing Systems - NeurIPS, 2022.


              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> Jun,&nbsp2022 </th>
            <td>
              
                I have joined SonyAI, Japan as an assistant researcher. I will be working with the great Dr. <a href="https://sites.google.com/view/lingjuan-lyu/home">Lingjuan Lyu</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> May,&nbsp2022 </th>
            <td>
              
                Got travel funding from University of Sydney to attend <a href="https://sites.google.com/view/2022-workshop-bridgingmathstcs">AustMS Workshop on Bridging Maths and Computer Science</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> Sep,&nbsp2021 </th>
            <td>
              
                One paper got accepted in Conference on Neural Information Processing Systems - <a href="https://nips.cc/">NeurIPS, 2021</a>.


              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> Aug,&nbsp2021 </th>
            <td>
              
                One paper got accepted in International Conference on Computer Vision - <a href="https://iccv2021.thecvf.com/home">ICCV, 2021</a>. For details, please visit <a href="https://awaisrauf.github.io/robust_uda">project page</a>.


              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> Jun,&nbsp2021 </th>
            <td>
              
                I am serving as a reviewer for three conferences (CVPRâ€™21, <a href="https://iclr.cc/">ICLRâ€™22</a>, <a href="http://iccv2021.thecvf.com">ICCVâ€™21</a>) and two workshops (CVPRWâ€™21 on Adversarial ML in the Real World <a href="https://aisecure-workshop.github.io/amlcvpr2021/">(link)</a> and ICLRWâ€™21 on Security and Safety in ML Systems <a href="https://aisecure-workshop.github.io/aml-iclr2021/">(link)</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> Jun,&nbsp2020 </th>
            <td>
              
                One paper got accepted in IEEE Transactions on Neural Networks and Learning Systems - <a href="https://cis.ieee.org/publications/t-neural-networks-and-learning-systems">TNNLS</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
       
      <!-- limit: site.news_limit  -->
        
       
      <!-- limit: site.news_limit  -->
        
       
      <!-- limit: site.news_limit  -->
        
       
      <!-- limit: site.news_limit  -->
        
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> Jul,&nbsp2018 </th>
            <td>
              
                Won <a href="http://awaisrauf.github.io/election_prediction">Election Prediction Contest</a> held by <a href="https://ignite.org.pk/">Ignite</a>,
 <a href="http://redbuffer.net/">Red Buffer</a>, <a href="http://deeplinks.pk/">DeepLinks</a> and <a href="https://twitter.com/CodeforPakistan/status/1024623283973578755">Code for Pakistan</a> <a href="https://propakistani.pk/2018/08/01/first-ever-election-prediction-contest-in-pakistan-concludes/">(link)</a>.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
          <tr>
            <!-- &nbsp is for non-line-breaking space. -->
            <th> Jul,&nbsp2017 </th>
            <td>
              
                <a href="https://www.nvidia.com">NVIDIA</a> has accepted our proposal for the <a href="https://developer.nvidia.com/academic_gpu_seeding">grant of Titan-X GPU</a> to support research.

              
            </td>
          </tr>
          
       
      <!-- limit: site.news_limit  -->
        
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="Awais.NeurIPS" class="col-sm-8">
    
      <div class="title">MixACM: Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fengwei, Zhou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chuanlong, Xie,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jiawei, Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sung-Ho, Bae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zhenguo, Li
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Conference on Neural Information Processing Systems(NeurIPS)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICCV</abbr>
    
  
  </div>

  <div id="Awais.ICCV21" class="col-sm-8">
    
      <div class="title">Adversarial Robustness for Unsupervised Domain Adaptation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fengwei, Zhou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hang, Xu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lanqing, Hong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ping, Luo,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sung-Ho, Bae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Zhenguo, Li
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Internatioanl Conference on Computer Vision (ICCV)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://awaisrauf.github.io/robust_uda" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="https://arxiv.org/pdf/2109.00946.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Extensive Unsupervised Domain Adaptation (UDA) studies have shown great success in practice by learning transferable representations across a labeled source domain and an unlabeled target domain with deep models. However, previous works focus on improving the generalization ability of UDA models on clean examples without considering the adversarial robustness, which is crucial in real-world applications. Conventional adversarial training methods are not suitable for the adversarial robustness on the unlabeled target domain of UDA since they train models with adversarial examples generated by the supervised loss function. In this work, we leverage intermediate representations learned by multiple robust ImageNet models to improve the robustness of UDA models. Our method works by aligning the features of the UDA model with the robust features learned by ImageNet pre-trained models along with domain adaptation training. It utilizes both labeled and unlabeled domains and instills robustness without any adversarial intervention or label requirement during domain adaptation training. Experimental results show that our method significantly improves adversarial robustness compared to the baseline while keeping clean accuracy on various UDA benchmarks.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TNNLS</abbr>
    
  
  </div>

  <div id="Awais.TNNLS20" class="col-sm-8">
    
      <div class="title">Revisiting Internal Covariant Shift for Batch Normalization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Md. Tauhid Bin, Iqbal,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sung-Ho, Bae
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Neural Networks and Learning Systems</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9238401" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite the success of Batch Normalization (BatchNorm) and a plethora of its variants, the exact reasons for its success are still shady. The original BatchNorm paper explained it as a mechanism that reduces the Internal Covariate Shift (ICS), i.e., the distribution shifts in the input of the layers during training. Recently, some papers manifested skepticism on this hypothesis and provided \textitalternative explanations for the success of BatchNorm, such as the applicability of very high learning rates and the ability to smooth the landscape in optimization. In this work, we counter this  textit alternative arguments by demonstrating the importance of reduction in ICS following an empirical approach. We demonstrated various ways to achieve the above-mentioned alternative properties without any performance boost. In this light, we explored the importance of different BatchNorm parameters (i.e., batch statistics, affine transformation parameters) by visualizing their effectiveness in the performance and analyzed their connections with ICS. Afterward, we showed a different normalization scheme that fulfills all alternative explanations except reduction in ICS. Despite having all the alternative properties, we observed its poor performance, which nullifies the alternative claims rather signifies the importance of the ICS reduction. We performed comprehensive experiments on many variants of BatchNorm, finding that all of them similarly reduce ICS.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Arxiv</abbr>
    
  
  </div>

  <div id="Awais.Arxiv20" class="col-sm-8">
    
      <div class="title">Towards Adversarially Robust Normalization Approach</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Awais, Muhammad</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fahad, Shamshad,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sung-Ho, Bae
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Under Review</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2006.11007.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Batch Normalization (BatchNorm) is effective for improving performance and accelerating the training of deep neural networks. However, it is also a cause of adversarial vulnerability. In this paper, we first investigated how BatchNorm causes this vulnerability. We observed that adversarial inputs tend to shift the distributions of the BatchNorm layer. This shift makes train-time estimated statistics of BatchNorm inaccurate. We hypothesize that these inaccurate statistics make models with BatchNorm more vulnerable to adversarial attacks. We empirically verified our hypothesis by conducting multiple experiments on a diverse set of architectures and datasets. Based on the insights from these experiments, we also proposed a robust version of BatchNorm. We experimentally show that models trained with RobustNorm perform better under adversarial settings while retaining the benefits of BatchNorm.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
</div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2023 Awais  .
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
