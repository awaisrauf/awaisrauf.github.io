---
---

@string{aps = {American Physical Society,}}


@article{Awais.arXiv23,
  abbr     = {arXiv},
  title    = {Foundational Models Defining a New Era in Vision: A Survey and Outlook},
  author   = {Awais, Muhammad and Muzammal, Naseer and Salman Khan and Rao Muhammad Anwer and Hisham Cholakkal and Mubarak Shah and Ming-Hsuan Yang and Fahad Shahbaz Khan},
  journal  = {Under Review (arXiv)},
  year     = {2023},
  month    = {March},
  selected = {true},
  pdf={https://arxiv.org/pdf/2307.13721.pdf},
  code={https://github.com/awaisrauf/Awesome-CV-Foundational-Models}

}

@article{Awais.arXiv,
  abbr     = {arXiv},
  title    = {FROD: Robust Object Detection for Free},
  author   = {Awais, Muhammad and Weiming, Zhuang and Lingjuan and Lyu and Sung-Ho, Bae},
  journal  = {Under Review (arXiv)},
  year     = {2023},
  month    = {March},
  selected = {true}
}

@article{Awais.NeurIPS22,
  abbr     = {NeurIPS},
  title    = {ZooD: Exploiting model zoo for out-of-distribution generalization},
  author   = {Qishi, Dong* and Awais, Muhammad and * and Fengwei Zhou and Chuanlong Xie and Tianyang Hu and Yongxin Yang and Sung-Ho, Bae and Zhenguo Li},
  journal  = {Conference on Neural Information Processing Systems (NeurIPS)},
  year     = {2022},
  month    = {September},
  selected = {true},
  pdf={https://proceedings.neurips.cc/paper_files/paper/2022/file/cd305fdee96836d5cc1de94577d71b61-Paper-Conference.pdf}
}

@article{Awais.NeurIPS,
  abbr={NeurIPS},
  title={MixACM: Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps},
  author={Awais, Muhammad and Fengwei, Zhou and Chuanlong, Xie and Jiawei, Li and Sung-Ho, Bae and Zhenguo, Li},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  abstract={Deep neural networks are susceptible to adversarially crafted, small and imperceptible changes in the natural inputs. The most effective defense mechanism against these examples is adversarial training which constructs adversarial examples during training by iterative maximization of loss. The model is then trained to minimize the loss on these constructed examples. This min-max optimization requires more data, larger capacity models, and additional computing resources. It also degrades the standard generalization performance of a model. Can we achieve robustness more efficiently? In this work, we explore this question from the perspective of knowledge transfer. First, we theoretically show the transferability of robustness from an adversarially trained teacher model to a student model with the help of mixup augmentation. Second, we propose a novel robustness transfer method called Mixup-Based Activated Channel Maps (MixACM) Transfer. MixACM transfers robustness from a robust teacher to a student by matching activated channel maps generated without expensive adversarial perturbations. Finally, extensive experiments on multiple datasets and different learning scenarios show our method can transfer robustness while also improving generalization on natural images.},
  year={2021},
  month={September},
  selected={true},
  pdf={https://proceedings.neurips.cc/paper_files/paper/2021/file/240c945bb72980130446fc2b40fbb8e0-Paper.pdf},
  webpage={https://awaisrauf.github.io/MixACM}
}

@article{Awais.ICCV21,
  abbr={ICCV},
  title={Adversarial Robustness for Unsupervised Domain Adaptation},
  author={Awais, Muhammad and Fengwei, Zhou and Hang, Xu and Lanqing, Hong and Ping, Luo and Sung-Ho, Bae and Zhenguo, Li},
  abstract={Extensive Unsupervised Domain Adaptation (UDA) studies have shown great success in practice by learning transferable representations across a labeled source domain and an unlabeled target domain with deep models. However, previous works focus on improving the generalization ability of UDA models on clean examples without considering the adversarial robustness, which is crucial in real-world applications. Conventional adversarial training methods are not suitable for the adversarial robustness on the unlabeled target domain of UDA since they train models with adversarial examples generated by the supervised loss function. In this work, we leverage intermediate representations learned by multiple robust ImageNet models to improve the robustness of UDA models. Our method works by aligning the features of the UDA model with the robust features learned by ImageNet pre-trained models along with domain adaptation training. It utilizes both labeled and unlabeled domains and instills robustness without any adversarial intervention or label requirement during domain adaptation training. Experimental results show that our method significantly improves adversarial robustness compared to the baseline while keeping clean accuracy on various UDA benchmarks.},
  journal={Internatioanl Conference on Computer Vision (ICCV)},
  year={2021},
  month={September},
  publisher=IEEE,
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  webpage={http://awaisrauf.github.io/robust_uda},
  html={http://awaisrauf.github.io/robust_uda},
  pdf={https://arxiv.org/pdf/2109.00946.pdf},
  selected={true}
}

@article{Awais.TNNLS20,
  abbr={TNNLS},
  title={Revisiting Internal Covariant Shift for Batch Normalization},
  author={Awais, Muhammad and Md. Tauhid Bin, Iqbal and Sung-Ho, Bae},
  abstract={Despite the success of Batch Normalization (BatchNorm) and a plethora of its variants, the exact reasons for its success are still shady. The original BatchNorm paper explained it as a mechanism that reduces the Internal Covariate Shift (ICS), i.e., the distribution shifts in the input of the layers during training. Recently, some papers manifested skepticism on this hypothesis and provided \textit{alternative explanations} for the success of BatchNorm, such as the applicability of very high learning rates and the ability to smooth the landscape in optimization. In this work, we counter this \ textit {alternative arguments} by demonstrating the importance of reduction in ICS following an empirical approach. We demonstrated various ways to achieve the above-mentioned alternative properties without any performance boost. In this light, we explored the importance of different BatchNorm parameters (i.e., batch statistics, affine transformation parameters) by visualizing their effectiveness in the performance and analyzed their connections with ICS. Afterward, we showed a different normalization scheme that fulfills all alternative explanations except reduction in ICS. Despite having all the alternative properties, we observed its poor performance, which nullifies the alternative claims rather signifies the importance of the ICS reduction. We performed comprehensive experiments on many variants of BatchNorm, finding that all of them similarly reduce ICS.},
  journal={IEEE Transactions on Neural Networks and Learning Systems (TNNLS)},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={2020},
  month={October},
  publisher=IEEE,
  doi={10.1109/TNNLS.2020.3026784},
  html={https://ieeexplore.ieee.org/document/9238401},
  webpage={https://ieeexplore.ieee.org/document/9238401},
  selected={true}
}

@article{Awais.Arxiv20,
  abbr={arXiv},
  title={Towards Adversarially Robust Normalization Approach},
  author={Awais, Muhammad and Fahad, Shamshad and Sung-Ho, Bae},
  abstract={Batch Normalization (BatchNorm) is effective for improving performance and accelerating the training of deep neural networks. However, it is also a cause of adversarial vulnerability. In this paper, we first investigated how BatchNorm causes this vulnerability. We observed that adversarial inputs tend to shift the distributions of the BatchNorm layer. This shift makes train-time estimated statistics of BatchNorm inaccurate. We hypothesize that these inaccurate statistics make models with BatchNorm more vulnerable to adversarial attacks. We empirically verified our hypothesis by conducting multiple experiments on a diverse set of architectures and datasets. Based on the insights from these experiments, we also proposed a robust version of BatchNorm. We experimentally show that models trained with RobustNorm perform better under adversarial settings while retaining the benefits of BatchNorm.},
  journal={Under Review},
  year={2020},
  month={June},
  publisher=Arxiv,
  url={https://arxiv.org/abs/2006.11007},
  pdf={https://arxiv.org/pdf/2006.11007.pdf},
  selected={true}
}

@article{Awais.JAIHC.19,
  abbr={JAIHC},
  title={Leveraging big data for politics: predicting general election of Pakistan using a novel rigged model},
  author={Awais, Muhammad and Saeed UL, Hassan and Ali, Ahmed},
  journal={Journal of Ambient Intelligence and Humanized Computing},
  year={2019},
  month={July},
  publisher=Springer,
  html={https://awaisrauf.github.io/election_prediction},
  selected={false}
}

@article{Fahad.ICCVw.19,
  abbr={ICCVw},
  title={Adaptive Ptych: Leveraging Image Adaptive Generative Priors for Subsampled Fourier Ptychography},
  author={Fahad, Shamshad and Asif, Hanif and Awais, Muhammad and Farwa, Abbas and Ali, Ahmed},
  abstract={Recently pretrained generative models have shown promising results for subsampled Fourier Ptychography (FP) in terms of quality of reconstruction for extremely low sampling rates. However, the representation capabilities of these pretrained generators do not capture the full distribution for complex classes of images, such as human faces or numbers, resulting in representation error. Moreover, recent studies have shown that these pretrained generative priors struggle at high-resolution in imaging inverse problems for reconstructing a faithful estimate of the true image, potentially due to mode collapse issue. To mitigate the issue of representation error of pretrained generative models for subsampled FP, we propose to make pretrained generator image adaptive by modifying it to better represent a single image (at test time) that is consistent with the subsampled FP measurements. Our experimental results demonstrate the superiority of the proposed approach over recent subsampled FP methods in terms of both quantitative metrics and visual quality},
  journal={International Conference on Computer Vision Workshops},
  year={2019},
  month={September},
  publisher=IEEE,
  pdf={https://openaccess.thecvf.com/content_ICCVW_2019/papers/LCI/Shamshad_Adaptive_Ptych_Leveraging_Image_Adaptive_Generative_Priors_for_Subsampled_Fourier_ICCVW_2019_paper.pdf},
  selected={false}
}

@article{Fahad.NIPSw.18,
  abbr={NIPSw},
  title={Leveraging Deep Stein's Unbiased Risk Estimator for Unsupervised X-ray Denoising},
  author={Fahad, Shamshad and Awais, Muhammad and Muhammad, Asim and Ali, Ahmed},
  journal={Neural Information Processing Systems Workshops},
  year={2018},
  html={http://awaisrauf.github.io/xray-denoising},
  selected={false}
}

@article{Asim.ICTD.17,
  abbr={ICTD},
  title={Introducing Data mining for Predicting trends in School Education of Pakistan: Preliminary results and Future Directions},
  author={Muhammad, Asim and Fahad, Shamshad and Awais, Muhammad and Ali, Ahmed},
  journal={Conference on Information and Communication Technologies and Development },
  year={2017},
  html={https://dl.acm.org/doi/10.1145/3136560.3136597},
  selected={false}
}

